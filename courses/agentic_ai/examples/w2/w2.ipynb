{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4a5120",
   "metadata": {},
   "source": [
    "# Week 2: Machine Learning Essentials\n",
    "[back](../README.md)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Welcome to Week 2 of the Agentic AI program. This week focuses on bridging the gap between basic Python programming and intelligent agent behavior by introducing machine learning fundamentals. You will explore how to train models that enable agents to make predictions, classify data, and reason about the world.\n",
    "\n",
    "**Key Characteristics of ML Models:**\n",
    "- **Learning from data**: Models improve their performance by analyzing examples.\n",
    "- **Predictive intelligence**: Trained models can make predictions on new data.\n",
    "\n",
    "For AI agents, machine learning is essential. It enables agents to:\n",
    "- Predict optimal actions based on historical outcomes.\n",
    "- Classify incoming requests for appropriate routing.\n",
    "- Rank search results by relevance.\n",
    "- Estimate resource requirements for tasks.\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "By the end of this week, you will be able to:\n",
    "- Understand the ML workflow.\n",
    "- Save and load trained models using pickle.\n",
    "- Create reusable ML tools.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "### The ML Workflow\n",
    "\n",
    "Machine learning projects typically follow a standard workflow:\n",
    "\n",
    "![ML Workflow](w2_mlworkflow.png)\n",
    "\n",
    "\n",
    "### Common Python Frameworks for Machine Learning\n",
    "\n",
    "Here are some popular Python frameworks used in machine learning:\n",
    "\n",
    "- **scikit-learn**: A simple and efficient library for data mining and machine learning, ideal for beginners and traditional ML tasks.\n",
    "- **PyTorch**: A flexible and dynamic deep learning framework, widely used for research and production.\n",
    "- **TensorFlow**: An end-to-end open-source platform for machine learning, known for its scalability and support for production-grade models.\n",
    "- **XGBoost**: An optimized gradient boosting library designed for speed and performance, often used in competitive machine learning.\n",
    "- **LightGBM**: A gradient boosting framework that is highly efficient and scalable, particularly for large datasets.\n",
    "\n",
    "This week, we will use **scikit-learn** to develop and deploy ML models. Its simplicity and efficiency make it an excellent choice for understanding the fundamentals of the ML workflow.\n",
    "\n",
    "### Correlation and Causation\n",
    "\n",
    "**Correlation** refers to a statistical relationship between two variables, where changes in one variable are associated with changes in another. However, correlation does not imply causation.\n",
    "\n",
    "**Causation** means that one variable directly affects another, establishing a cause-and-effect relationship.\n",
    "\n",
    "#### Example 1: Correlation (No Causation)\n",
    "- **Observation**: Students who study in a reputed college tend to score higher on exams.\n",
    "- **Explanation**: While there is a correlation between reputed college and exam scores, other factors like student abilities, prior knowledge, and exam difficulty also play a role. Correlation alone does not prove that studying more results in higher scores.\n",
    "\n",
    "#### Example 2: Causation\n",
    "- **Observation**: Providing additional tutoring sessions improves student performance.\n",
    "- **Explanation**: Controlled experiments can establish that tutoring directly impacts performance, demonstrating a causal relationship.\n",
    "\n",
    "Understanding the distinction between correlation and causation is critical in machine learning to avoid making incorrect assumptions about relationships in data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554af9e8",
   "metadata": {},
   "source": [
    "### Introduction to Linear Regression\n",
    "\n",
    "Linear regression is a fundamental statistical method used to model the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship, where changes in the independent variable(s) result in proportional changes in the dependent variable.\n",
    "\n",
    "#### Key Features:\n",
    "- **Simple Linear Regression**: Involves one independent variable.\n",
    "- **Multiple Linear Regression**: Involves two or more independent variables.\n",
    "\n",
    "Linear regression is widely used for predictive modeling and understanding relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Read the Salary_dataset.csv file\n",
    "salary_data = pd.read_csv('Salary_Data.csv')\n",
    "Y = salary_data['Salary']\n",
    "X = salary_data[['YearsExperience']]\n",
    "# Create and fit the linear regression model\n",
    "salarymodel = LinearRegression()\n",
    "salarymodel.fit(X, Y)\n",
    "\n",
    "# Display the coefficients\n",
    "print(\"Intercept:\", salarymodel.intercept_)\n",
    "print(\"Coefficient:\", salarymodel.coef_)\n",
    "print(\"Model R^2 Score:\", salarymodel.score(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d192153",
   "metadata": {},
   "source": [
    "Machine learning (ML) models play a pivotal role in enhancing the intelligence of AI agents. By integrating ML models, AI agents can analyze data, make predictions, and adapt to dynamic environments. Here's how ML models can be utilized within AI agents:\n",
    "\n",
    "1. **Training the Model**: Begin by training the ML model on a relevant dataset. For instance, in the case of predicting salaries based on years of experience, the model is trained using historical data to learn the relationship between the input features and the target variable.\n",
    "\n",
    "2. **Saving the Model**: Once trained, the model is serialized and saved using tools like `pickle`. This ensures that the model can be reused without retraining, saving computational resources.\n",
    "\n",
    "Pickle files are used to serialize and save machine learning models, enabling AI agents to load and reuse trained models without retraining. This ensures efficient deployment, allowing agents to make predictions or decisions in real-time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfddc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('salarymodel.pkl', 'wb') as file:\n",
    "    pickle.dump(salarymodel, file)\n",
    "\n",
    "print(\"Model saved to salarymodel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickled model\n",
    "with open('salarymodel.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Example: Predict salary for a given number of years of experience\n",
    "example_years_experience = [[float(input(\"Enter the number of years of experience: \"))]]\n",
    "predicted_salary = loaded_model.predict(example_years_experience)\n",
    "\n",
    "print(f\"Predicted Salary for {example_years_experience[0][0]} years of experience: {predicted_salary[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683f9d0",
   "metadata": {},
   "source": [
    "\n",
    "## Student Performance Case Study\n",
    "\n",
    "\n",
    "The Student Performance dataset, available on **Kaggle**, contains data on various factors influencing student academic performance. This dataset provides a practical example for understanding how multiple variables contribute to academic success and can be used to train regression models that predict exam scores based on the provided features.\n",
    "\n",
    "**Dataset Variables:**\n",
    "- **Hours Studied**: Total number of hours spent studying by each student.\n",
    "- **Previous Scores**: Scores obtained by students in previous tests.\n",
    "- **Extracurricular Activities**: Indicates whether the student participates in extracurricular activities (Yes/No).\n",
    "- **Sleep Hours**: Average number of hours of sleep the student had per day.\n",
    "- **Sample Question Papers Practiced**: Number of sample question papers the student practiced.\n",
    "- **Performance Index**: A measure of the overall performance of each student. The performance index ranges from 10 to 100, with higher values indicating better performance.\n",
    "\n",
    "Download link: [Student Performance Dataset](https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression/data#:~:text=calendar_view_week-,Student_Performance,-.csv)\n",
    "\n",
    "### The ML Workflow\n",
    "\n",
    "- **Goal**: Predicting the student performance index for given data set variables.\n",
    "- **Explore and prepare**: Analyze and preprocess the dataset to ensure data integrity and quality.\n",
    "- **Train and model**: Use scikit-learn to train regression models on the dataset.\n",
    "- **Deploy**: Save the trained model to integrate it into an application.\n",
    "- **Monitor and manage**: Evaluate the model's performance over time and update it as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Student_Performance.csv file\n",
    "student_data = pd.read_csv('Student_Performance.csv')\n",
    "# Display the first few rows of the dataset\n",
    "print(student_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct column names by removing spaces\n",
    "student_data.columns = student_data.columns.str.replace(' ', '')\n",
    "\n",
    "# Convert 'Extracurricular_Activities' to numerical values (Yes -> 1, No -> 0)\n",
    "student_data['ExtracurricularActivities'] = student_data['ExtracurricularActivities'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Display the updated dataset\n",
    "print(student_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034805ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates\n",
    "duplicates = student_data[student_data.duplicated()]\n",
    "print(f\"Number of duplicate rows: {len(duplicates)}\")\n",
    "\n",
    "# Drop duplicates\n",
    "student_data = student_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for rows with null values in the dataset\n",
    "rows_with_null = student_data[student_data.isnull().any(axis=1)]\n",
    "print(f\"Number of rows with null values: {len(rows_with_null)}\")\n",
    "# Describe student_data using statistics\n",
    "student_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = student_data.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sn.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75802d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See unique values\n",
    "print(student_data[\"SleepHours\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First set figure size\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "def count_plot(column_name, data, hue=None, rotation=0):\n",
    "    \"\"\"\n",
    "    1) Input: column name, column data type must be object or categorical\n",
    "    2) Output: Count plot using seaborn module, unique values in x-axis and frequency in y-axis\n",
    "    3) Bar labels show frequency of each unique value above each column in the graph\n",
    "    \"\"\"\n",
    "    graph = sn.countplot(x=column_name, data=data, hue=hue, order=data[column_name].value_counts().index)\n",
    "    for container in graph.containers:\n",
    "        graph.bar_label(container)\n",
    "        \n",
    "    plt.xticks(rotation=rotation)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the correct DataFrame\n",
    "count_plot(column_name=\"SleepHours\", data=student_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(column_name=\"SampleQuestionPapersPracticed\", data=student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Indipendent and Dependent Variable\n",
    "X = student_data.drop(\"PerformanceIndex\", axis=1)\n",
    "y = student_data[\"PerformanceIndex\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b0fb3",
   "metadata": {},
   "source": [
    "# Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split package from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider PreviousScores as correlation is significant\n",
    "X1 = X[['PreviousScores']]\n",
    "y1 = y\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=40)\n",
    "# The random_state parameter ensures reproducibility of the train-test split.\n",
    "# By setting random_state=42, the split will always produce the same training and testing sets\n",
    "# when the code is run multiple times, making the results consistent and comparable.\n",
    "print(X1_train.shape, X1_test.shape, y1_train.shape, y1_test.shape)\n",
    "# create object from RandomForestRegressor\n",
    "case1model = LinearRegression()\n",
    "case1model.fit(X1_train, y1_train)\n",
    "# Print the coefficients, intercept, and score of the model\n",
    "print(\"Coefficients:\", case1model.coef_)\n",
    "print(\"Intercept:\", case1model.intercept_)\n",
    "print(\"Model R^2 Score:\", case1model.score(X1_train, y1_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, consider only HoursStudied and PreviousScores as features given their correlation\n",
    "X2 = X[['HoursStudied', 'PreviousScores']]\n",
    "y2 = y\n",
    "# Split the data into training and testing sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=40)\n",
    "case2model = LinearRegression()\n",
    "case2model.fit(X2_train, y2_train)\n",
    "# Print the coefficients, intercept, and score of the model\n",
    "print(\"Coefficients:\", case2model.coef_)\n",
    "print(\"Intercept:\", case2model.intercept_)\n",
    "print(\"Model R^2 Score:\", case2model.score(X2_train, y2_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Predict the target values for the test data\n",
    "y1_pred = case1model.predict(X1_test)\n",
    "y2_pred = case2model.predict(X2_test)\n",
    "# Calculate R² score\n",
    "r1 = r2_score(y1_test, y1_pred)\n",
    "r2 = r2_score(y2_test, y2_pred)\n",
    "print(f\"R² Score for Case 1 Model: {r1}\")\n",
    "print(f\"R² Score for Case 2 Model: {r2}\")\n",
    "\n",
    "\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
