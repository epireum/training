{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4a5120",
   "metadata": {},
   "source": [
    "# Week 2: Machine Learning Essentials\n",
    "[back](../README.md)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Welcome to Week 2 of the Agentic AI program. This week focuses on bridging the gap between basic Python programming and intelligent agent behavior by introducing machine learning fundamentals. You will explore how to train models that enable agents to make predictions, classify data, and reason about the world.\n",
    "\n",
    "**Key Characteristics of ML Models:**\n",
    "- **Learning from data**: Models improve their performance by analyzing examples.\n",
    "- **Predictive intelligence**: Trained models can make predictions on new data.\n",
    "\n",
    "For AI agents, machine learning is essential. It enables agents to:\n",
    "- Predict optimal actions based on historical outcomes.\n",
    "- Classify incoming requests for appropriate routing.\n",
    "- Rank search results by relevance.\n",
    "- Estimate resource requirements for tasks.\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "By the end of this week, you will be able to:\n",
    "- Understand the ML workflow.\n",
    "- Save and load trained models using pickle.\n",
    "- Create reusable ML tools.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "### The ML Workflow\n",
    "\n",
    "Machine learning projects typically follow a standard workflow:\n",
    "\n",
    "![ML Workflow](w2_mlworkflow.png)\n",
    "\n",
    "\n",
    "### Common Python Frameworks for Machine Learning\n",
    "\n",
    "Here are some popular Python frameworks used in machine learning:\n",
    "\n",
    "- **scikit-learn**: A simple and efficient library for data mining and machine learning, ideal for beginners and traditional ML tasks.\n",
    "- **PyTorch**: A flexible and dynamic deep learning framework, widely used for research and production.\n",
    "- **TensorFlow**: An end-to-end open-source platform for machine learning, known for its scalability and support for production-grade models.\n",
    "- **XGBoost**: An optimized gradient boosting library designed for speed and performance, often used in competitive machine learning.\n",
    "- **LightGBM**: A gradient boosting framework that is highly efficient and scalable, particularly for large datasets.\n",
    "\n",
    "This week, we will use **scikit-learn** to develop and deploy ML models. Its simplicity and efficiency make it an excellent choice for understanding the fundamentals of the ML workflow.\n",
    "\n",
    "### Correlation and Causation\n",
    "\n",
    "**Correlation** refers to a statistical relationship between two variables, where changes in one variable are associated with changes in another. However, correlation does not imply causation.\n",
    "\n",
    "**Causation** means that one variable directly affects another, establishing a cause-and-effect relationship.\n",
    "\n",
    "#### Example 1: Correlation (No Causation)\n",
    "- **Observation**: Students who study in a reputed college tend to score higher on exams.\n",
    "- **Explanation**: While there is a correlation between reputed college and exam scores, other factors like student abilities, prior knowledge, and exam difficulty also play a role. Correlation alone does not prove that studying more results in higher scores.\n",
    "\n",
    "#### Example 2: Causation\n",
    "- **Observation**: Providing additional tutoring sessions improves student performance.\n",
    "- **Explanation**: Controlled experiments can establish that tutoring directly impacts performance, demonstrating a causal relationship.\n",
    "\n",
    "Understanding the distinction between correlation and causation is critical in machine learning to avoid making incorrect assumptions about relationships in data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554af9e8",
   "metadata": {},
   "source": [
    "### Introduction to Linear Regression\n",
    "\n",
    "Linear regression is a fundamental statistical method used to model the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship, where changes in the independent variable(s) result in proportional changes in the dependent variable.\n",
    "\n",
    "#### Key Features:\n",
    "- **Simple Linear Regression**: Involves one independent variable.\n",
    "- **Multiple Linear Regression**: Involves two or more independent variables.\n",
    "![Linear Regression](w2_linearRegression.png)\n",
    "\n",
    "Linear regression is widely used for predictive modeling and understanding relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5dbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907b6784",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Salary_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Read the Salary_dataset.csv file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m salary_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSalary_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m Y \u001b[38;5;241m=\u001b[39m salary_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m salary_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYearsExperience\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Salary_dataset.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Read the Salary_dataset.csv file\n",
    "salary_data = pd.read_csv('Salary_dataset.csv')\n",
    "Y = salary_data['Salary']\n",
    "X = salary_data[['YearsExperience']]\n",
    "# Create and fit the linear regression model\n",
    "salarymodel = LinearRegression()\n",
    "salarymodel.fit(X, Y)\n",
    "\n",
    "# Display the coefficients\n",
    "print(\"Intercept:\", salarymodel.intercept_)\n",
    "print(\"Coefficient:\", salarymodel.coef_)\n",
    "print(\"Model R^2 Score:\", salarymodel.score(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d192153",
   "metadata": {},
   "source": [
    "Machine learning (ML) models play a pivotal role in enhancing the intelligence of AI agents. By integrating ML models, AI agents can analyze data, make predictions, and adapt to dynamic environments. Here's how ML models can be utilized within AI agents:\n",
    "\n",
    "1. **Training the Model**: Begin by training the ML model on a relevant dataset. For instance, in the case of predicting salaries based on years of experience, the model is trained using historical data to learn the relationship between the input features and the target variable.\n",
    "\n",
    "2. **Saving the Model**: Once trained, the model is serialized and saved using tools like `pickle`. This ensures that the model can be reused without retraining, saving computational resources.\n",
    "\n",
    "Pickle files are used to serialize and save machine learning models, enabling AI agents to load and reuse trained models without retraining. This ensures efficient deployment, allowing agents to make predictions or decisions in real-time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfddc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('salarymodel.pkl', 'wb') as file:\n",
    "    pickle.dump(salarymodel, file)\n",
    "\n",
    "print(\"Model saved to salarymodel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickled model\n",
    "with open('salarymodel.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Example: Predict salary for a given number of years of experience\n",
    "example_years_experience = [[float(input(\"Enter the number of years of experience: \"))]]\n",
    "predicted_salary = loaded_model.predict(example_years_experience)\n",
    "\n",
    "print(f\"Predicted Salary for {example_years_experience[0][0]} years of experience: {predicted_salary[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683f9d0",
   "metadata": {},
   "source": [
    "\n",
    "## Student Performance Case Study\n",
    "\n",
    "\n",
    "The Student Performance dataset, available on [Kaggle](https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression/data), contains data on various factors influencing student academic performance. This dataset provides a practical example for understanding how multiple variables contribute to academic success and can be used to train regression models that predict exam scores based on the provided features.\n",
    "\n",
    "**Dataset Variables:**\n",
    "- **Hours Studied**: Total number of hours spent studying by each student.\n",
    "- **Previous Scores**: Scores obtained by students in previous tests.\n",
    "- **Extracurricular Activities**: Indicates whether the student participates in extracurricular activities (Yes/No).\n",
    "- **Sleep Hours**: Average number of hours of sleep the student had per day.\n",
    "- **Sample Question Papers Practiced**: Number of sample question papers the student practiced.\n",
    "- **Performance Index**: A measure of the overall performance of each student. The performance index ranges from 10 to 100, with higher values indicating better performance.\n",
    "\n",
    "Download link: [Student Performance Dataset](https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression/data#:~:text=calendar_view_week-,Student_Performance,-.csv)\n",
    "\n",
    "### The ML Workflow\n",
    "\n",
    "- **Goal**: Predicting the student performance index for given data set variables.\n",
    "- **Explore and prepare**: Analyze and preprocess the dataset to ensure data integrity and quality.\n",
    "- **Train and model**: Use scikit-learn to train regression models on the dataset.\n",
    "- **Deploy**: Save the trained model to integrate it into an application.\n",
    "- **Monitor and manage**: Evaluate the model's performance over time and update it as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Student_Performance.csv file\n",
    "student_data = pd.read_csv('Student_Performance.csv')\n",
    "# Display the first few rows of the dataset\n",
    "print(student_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct column names by removing spaces\n",
    "student_data.columns = student_data.columns.str.replace(' ', '')\n",
    "\n",
    "# Convert 'Extracurricular_Activities' to numerical values (Yes -> 1, No -> 0)\n",
    "student_data['ExtracurricularActivities'] = student_data['ExtracurricularActivities'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Display the updated dataset\n",
    "print(student_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034805ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates\n",
    "duplicates = student_data[student_data.duplicated()]\n",
    "print(f\"Number of duplicate rows: {len(duplicates)}\")\n",
    "\n",
    "# Drop duplicates\n",
    "student_data = student_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for rows with null values in the dataset\n",
    "rows_with_null = student_data[student_data.isnull().any(axis=1)]\n",
    "print(f\"Number of rows with null values: {len(rows_with_null)}\")\n",
    "# Describe student_data using statistics\n",
    "student_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = student_data.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sn.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75802d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See unique values\n",
    "print(student_data[\"SleepHours\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First set figure size\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "def count_plot(column_name, data, hue=None, rotation=0):\n",
    "    \"\"\"\n",
    "    1) Input: column name, column data type must be object or categorical\n",
    "    2) Output: Count plot using seaborn module, unique values in x-axis and frequency in y-axis\n",
    "    3) Bar labels show frequency of each unique value above each column in the graph\n",
    "    \"\"\"\n",
    "    graph = sn.countplot(x=column_name, data=data, hue=hue, order=data[column_name].value_counts().index)\n",
    "    for container in graph.containers:\n",
    "        graph.bar_label(container)\n",
    "        \n",
    "    plt.xticks(rotation=rotation)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the correct DataFrame\n",
    "count_plot(column_name=\"SleepHours\", data=student_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(column_name=\"SampleQuestionPapersPracticed\", data=student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Indipendent and Dependent Variable\n",
    "X = student_data.drop(\"PerformanceIndex\", axis=1)\n",
    "y = student_data[\"PerformanceIndex\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b0fb3",
   "metadata": {},
   "source": [
    "# Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split package from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider PreviousScores as correlation is significant\n",
    "X1 = X[['PreviousScores']]\n",
    "y1 = y\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=40)\n",
    "# The random_state parameter ensures reproducibility of the train-test split.\n",
    "# By setting random_state=42, the split will always produce the same training and testing sets\n",
    "# when the code is run multiple times, making the results consistent and comparable.\n",
    "print(X1_train.shape, X1_test.shape, y1_train.shape, y1_test.shape)\n",
    "# create object from RandomForestRegressor\n",
    "case1model = LinearRegression()\n",
    "case1model.fit(X1_train, y1_train)\n",
    "# Print the coefficients, intercept, and score of the model\n",
    "print(\"Coefficients:\", case1model.coef_)\n",
    "print(\"Intercept:\", case1model.intercept_)\n",
    "print(\"Model R^2 Score:\", case1model.score(X1_train, y1_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, consider only HoursStudied and PreviousScores as features given their correlation\n",
    "X2 = X[['HoursStudied', 'PreviousScores']]\n",
    "y2 = y\n",
    "# Split the data into training and testing sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=40)\n",
    "case2model = LinearRegression()\n",
    "case2model.fit(X2_train, y2_train)\n",
    "# Print the coefficients, intercept, and score of the model\n",
    "print(\"Coefficients:\", case2model.coef_)\n",
    "print(\"Intercept:\", case2model.intercept_)\n",
    "print(\"Model R^2 Score:\", case2model.score(X2_train, y2_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Predict the target values for the test data\n",
    "y1_pred = case1model.predict(X1_test)\n",
    "y2_pred = case2model.predict(X2_test)\n",
    "# Calculate R² score\n",
    "r1 = r2_score(y1_test, y1_pred)\n",
    "r2 = r2_score(y2_test, y2_pred)\n",
    "print(f\"R² Score for Case 1 Model: {r1}\")\n",
    "print(f\"R² Score for Case 2 Model: {r2}\")\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8135a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Lets consider all features to build the linear regression equation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Print the coefficients and intercept of the model\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Model R^2 Score:\", model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace3aca",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Lets make a feature variable using parameteres with low correlation\n",
    "X[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the case1model to a pickle file\n",
    "with open('case1model.pkl', 'wb') as file:\n",
    "    pickle.dump(case1model, file)\n",
    "\n",
    "print(\"case1model saved to case1model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caa220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict the PerformanceIndex for a new data point\n",
    "new_data_point = np.array([[8, 85, 1, 7, 3]])  # Example input: [HoursStudied, PreviousScores, ExtracurricularActivities, SleepHours, SampleQuestionPapersPracticed]\n",
    "predicted_performance_index = case1model.predict(new_data_point)\n",
    "\n",
    "print(f\"Predicted Performance Index: {predicted_performance_index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the pickled model\n",
    "with open('case1model.pkl', 'rb') as file:\n",
    "    ai_agent = pickle.load(file)\n",
    "\n",
    "# Ensure the loaded model is a trained LinearRegression model\n",
    "if isinstance(ai_agent, LinearRegression):\n",
    "    print(\"AI Agent loaded successfully!\")\n",
    "\n",
    "    # Example: Predict the PerformanceIndex for a new data point\n",
    "    print(\"Enter the following details to predict the Performance Index:\")\n",
    "    hours_studied = float(input(\"Hours Studied: \"))\n",
    "    previous_scores = float(input(\"Previous Scores: \"))\n",
    "    extracurricular_activities = int(input(\"Extracurricular Activities (1 for Yes, 0 for No): \"))\n",
    "    sleep_hours = float(input(\"Sleep Hours: \"))\n",
    "    sample_question_papers_practiced = int(input(\"Sample Question Papers Practiced: \"))\n",
    "\n",
    "    # Create a new data point\n",
    "    new_data_point = np.array([[hours_studied, previous_scores, extracurricular_activities, sleep_hours, sample_question_papers_practiced]])\n",
    "\n",
    "    # Predict using the AI agent\n",
    "    predicted_performance_index = ai_agent.predict(new_data_point)\n",
    "\n",
    "    print(f\"Predicted Performance Index: {predicted_performance_index[0]}\")\n",
    "else:\n",
    "    raise ValueError(\"Loaded model is not a LinearRegression instance. Ensure the correct model is saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f524ded",
   "metadata": {},
   "source": [
    "# Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into two subsets based on ExtracurricularActivities\n",
    "with_activities = student_data[student_data['ExtracurricularActivities'] == 1]\n",
    "without_activities = student_data[student_data['ExtracurricularActivities'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_and_evaluate_model(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Train a Linear Regression model and evaluate its performance.\n",
    "\n",
    "    Parameters:\n",
    "    - X: pandas.DataFrame, features\n",
    "    - y: pandas.Series, target variable\n",
    "    - test_size: float, proportion of the dataset to include in the test split\n",
    "    - random_state: int, random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing R² score, MAE, and MSE\n",
    "    \"\"\"\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target values for the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Validate the model\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"R² Score: {r2}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "    return {\"R² Score\": r2, \"Mean Absolute Error\": mae, \"Mean Squared Error\": mse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31484cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(with_activities.drop(\"PerformanceIndex\", axis=1), with_activities[\"PerformanceIndex\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e157fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(without_activities.drop(\"PerformanceIndex\", axis=1), without_activities[\"PerformanceIndex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a510b",
   "metadata": {},
   "source": [
    "Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(2000)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Standardize and split (unchanged)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model with explicit dtypes\n",
    "model_nn = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu', dtype='float32'),\n",
    "    Dense(32, activation='relu', dtype='float32'),\n",
    "    Dense(1, dtype='float32')\n",
    "])\n",
    "\n",
    "# COMPILE with run_eagerly=True HERE (Keras 3.0+ fix)\n",
    "model_nn.compile(\n",
    "    optimizer='adam', \n",
    "    loss='mse', \n",
    "    metrics=['mae'],\n",
    "    run_eagerly=True  # <- MOVED TO COMPILE\n",
    ")\n",
    "\n",
    "# Train WITHOUT run_eagerly parameter\n",
    "history = model_nn.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate (unchanged)\n",
    "y_pred_nn = model_nn.predict(X_test)\n",
    "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
    "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "\n",
    "print(f\"Neural Network Model Performance:\")\n",
    "print(f\"Mean Squared Error: {mse_nn}\")\n",
    "print(f\"Mean Absolute Error: {mae_nn}\")\n",
    "print(f\"R² Score: {r2_nn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6861f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
